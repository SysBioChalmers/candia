"""
Module to manage models generated by PARAFAC.

If run, it will generate model and spectrum index files.
"""
import argparse
import inspect
import itertools
import logging
import sys
from os import path
from functools import partial
from pathlib import Path

import coloredlogs
import numpy as np
import pandas as pd
import pyarrow.feather as feather
import torch
import yaml

_this_filename = inspect.getframeinfo(inspect.currentframe()).filename
_this_path = Path(_this_filename).parent.resolve()
sys.path.append(str(_this_path.parent))

from util import msproc

logging.basicConfig(format=msproc.LOG_FORMAT, level=logging.INFO)
logger = logging.getLogger(__name__)
coloredlogs.install(fmt=msproc.LOG_FORMAT, level='INFO', logger=logger)


dtype_spectrum_index = {
    'swath_start': np.uint32,
    'rt_window': np.uint8,
    'ncomp': np.uint8,
    'model_id': np.uint32,
    'spectrum_num': np.uint16,
    'scan': np.uint32}


def main():
    """
    Create index of all models and spectra based only on experiment parameters.
    """
    args = get_args()
    root_dir = Path(args.config['root_dir'])
    
    model_index = index_all_models(args)
    model_index['path'] = model_index.apply(partial(_model_path_from_params,
                                                    root_dir / args.config['slices_location']),
                                            axis='columns')
    write_index(root_dir / args.config['model_index'], model_index, file_format='feather')
    logger.info('Wrote model index')

    spectrum_index = index_all_spectra(model_index.drop(columns='path'))
    write_index(root_dir / args.config['spectrum_index'], spectrum_index, file_format='feather')
    logger.info('Wrote spectrum index')


def index_all_models(args):
    """
    Associates a unique ID (index) to all model parameters combinations
    (int(swath_start * 100), rt_window, ncomp) -> ID

    :return: pandas.DataFrame with all combinations of model parameters and associated ID
    """
    swaths_adjusted_filename = Path(args.config['root_dir']) / args.config['swath_windows_adjusted']
    swath_starts = pd.read_csv(swaths_adjusted_filename)['swath_lower_adjusted'].values
    swath_starts = np.round(swath_starts * 100).astype(np.uint32)
    rt_windows = get_rt_windows(args)
    ncomp_range = range(args.config['parafac_min_comp'], args.config['parafac_max_comp'] + 1)

    model_params = list(itertools.product(swath_starts, range(len(rt_windows)), ncomp_range))
    model_index = pd.DataFrame(model_params, columns=['swath_start', 'rt_window', 'ncomp'])
    model_index = model_index.assign(model_id=model_index.index)

    return model_index


def index_all_spectra(model_index):
    """
    Associates a unique ID (index) to all spectra, across all models.

    :return: pandas.DataFrame with all combinations of model parameters and spectra,
             along with globally unique spectra IDs labelled as "scan" for the
             sake of downstream analysis software.
    """
    # Create list of ordinal spectrum numbers for each model
    # (e.g. for a model with ncomp = 3 -> [0, 1, 2])
    model_index = model_index.assign(
        spectrum_num=model_index.apply(lambda row: range(row['ncomp']),
                                       axis='columns'))

    # Expand each list of spectrum numbers into rows,
    # while keeping track of model ID.
    # Pattern from https://stackoverflow.com/a/39011596/10725218
    spectrum_num_per_model = (
        pd.DataFrame(model_index['spectrum_num'].tolist(),
                     index=model_index['model_id'])
        .stack()
        .reset_index(level=1, drop=True)
        .reset_index(name='spectrum_num')
    )

    # Obtain the list of all spectra, across all models
    spectrum_index = (
        model_index.drop(columns=['spectrum_num'])
        .merge(spectrum_num_per_model, on='model_id')
    )
    spectrum_index = spectrum_index.assign(scan=spectrum_index.index)

    # Reduce data size
    for column in spectrum_index.columns.values:
        spectrum_index[column] = spectrum_index[column].astype(dtype_spectrum_index[column])

    return spectrum_index


def get_rt_windows(args):
    window_size_sec = args.config['window_size_sec']
    with open(Path(args.config['root_dir']) / 'computed_values.yaml', 'r') as values_file:
        computed_values = yaml.load(values_file)
    rt_windows = np.arange(0, computed_values['max_rt'], window_size_sec)
    return rt_windows


def _model_path_from_params(slices_location, model_params):
    model_path = path.join(slices_location,
                           f"swath_lower_adjusted={model_params['swath_start'] / 100:.2f}",
                           f"rt_window={model_params['rt_window']:.1f}",
                           f"parafac_model_F{int(model_params['ncomp'])}.pt")
    return model_path


def spectrum_index_entries_for_model(model_params, spectrum_index):
    idx_for_this_model = ((spectrum_index['swath_start'] == np.round(model_params['swath_start'] * 100).astype(np.uint32)) &
                          (spectrum_index['rt_window'] == model_params['rt_window']) &
                          (spectrum_index['ncomp'] == model_params['ncomp']))
    return spectrum_index[idx_for_this_model]


def write_index(index_filename: str,
                index_df: pd.DataFrame,
                file_format: str,
                record_name: str = 'index'):
    if file_format == 'h5':
        with pd.HDFStore(index_filename, mode='w') as store:
            store[record_name] = index_df

    elif file_format == 'feather':
        feather.write_feather(index_df, index_filename)

    else:
        raise NotImplementedError


def read_index(index_filename: str, file_format: str = None, record_name: str = 'index') -> pd.DataFrame:
    if file_format is None:
        file_format = Path(index_filename).suffix[1:]

    if file_format == 'h5':
        with pd.HDFStore(index_filename, mode='w') as store:
            return store[record_name]
    elif file_format == 'feather':
        return feather.read_feather(index_filename)
    elif file_format == 'csv':
        return pd.read_csv(index_filename)
    elif file_format == 'tsv':
        return pd.read_csv(index_filename, sep='\t')
    else:
        raise NotImplementedError(index_filename)


def get_args():
    desc = 'Collect model evaluation results from all slices'
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('-c',
                        '--config',
                        required=True,
                        type=str,
                        help='YAML experiment config file')
    args = parser.parse_args()
    with open(args.config, 'r') as config_file:
        args.config = yaml.load(config_file, Loader=yaml.FullLoader)
    return args


def extract_mode_from_model_to_feather(model_filename: str, mode: int, output_filename: str):
    mode = get_mode_from_model(model_filename, mode)
    feather.write_feather(mode, output_filename)


def get_mode_from_model(model_filename: str, mode: int) -> pd.DataFrame:
    """
    Read PyTorch .pt file and extract single mode
    :param mode: 0, 1, 2
    :param model_filename: PyTorch .pt file
    :return:
    """
    model = torch.load(model_filename, map_location='cpu')
    mode_df = pd.DataFrame(model[mode].numpy(), dtype=np.float32)
    return mode_df


def test_index_all_spectra():
    model_params = list(itertools.product(range(2), range(2), range(1, 3)))
    model_index = pd.DataFrame(model_params,
                               columns=['swath_start', 'rt_window', 'ncomp'])
    model_index = model_index.assign(model_id=model_index.index)
    spectrum_index = index_all_spectra(model_index)

    expected_spectrum_index = np.array([[0, 0, 1, 0, 0, 0],
                                        [0, 0, 2, 1, 0, 1],
                                        [0, 0, 2, 1, 1, 2],
                                        [0, 1, 1, 2, 0, 3],
                                        [0, 1, 2, 3, 0, 4],
                                        [0, 1, 2, 3, 1, 5],
                                        [1, 0, 1, 4, 0, 6],
                                        [1, 0, 2, 5, 0, 7],
                                        [1, 0, 2, 5, 1, 8],
                                        [1, 1, 1, 6, 0, 9],
                                        [1, 1, 2, 7, 0, 10],
                                        [1, 1, 2, 7, 1, 11]])
    assert np.array_equal(spectrum_index.values, expected_spectrum_index)


if __name__ == '__main__':
    main()
